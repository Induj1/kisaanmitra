{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 5212747,
          "sourceType": "datasetVersion",
          "datasetId": 3032186
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style=\"font-family: 'Roboto', sans-serif; font-size: 32px; color: #008080;\"> Agricultural Pest Classification using Deep Learning: ResNet and InceptionV3\n",
        "\n",
        "![image.png](attachment:d2d24925-96dd-407b-8d02-f3db637d0023.png)\n",
        "    \n",
        "<h2 style=\"font-family: 'Roboto', sans-serif; font-size: 24px; color: #000000;\">Introduction:</h2>\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Welcome to this Kaggle notebook, where we explore the fascinating world of agricultural pest classification using the power of deep learning. In this project, we aim to assist farmers in effectively identifying and managing common agricultural pests using two powerful pre-trained deep learning models, ResNet and InceptionV3.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Agricultural pests pose significant threats to crop yield and quality, making their timely detection and appropriate management critical for sustainable agriculture. Traditional pest identification methods can be time-consuming and error-prone. Leveraging the capabilities of deep learning, we present an innovative solution that automates the classification process, providing farmers with a reliable and efficient tool for pest identification. Throughout this notebook, we will embark on a journey of data preprocessing, augmentation, and fine-tuning of ResNet and InceptionV3 models. We will explore transfer learning techniques to harness the knowledge of these state-of-the-art models while adapting them to our specific agricultural pest classification task. Furthermore, we will conduct thorough model evaluation, analyzing accuracy, loss, and generating insightful visualizations like confusion matrices to assess the performance of our models on different pest classes.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">By the end of this notebook, we hope to showcase the effectiveness of deep learning models in agricultural pest classification and inspire the adoption of advanced technologies for precision agriculture. So, let's dive in and witness the power of ResNet and InceptionV3 in identifying and mitigating the challenges posed by agricultural pests.\n",
        "\n",
        "#    Happy learning!"
      ],
      "metadata": {
        "id": "Qm2yBqdarJvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "PE2c5VbyrJvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive\n",
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot\n",
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QiFnbF60ZU2",
        "outputId": "29b92c48-290d-422d-905b-9941664ec5db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n",
            "E: Package 'libfluidsynth1' has no installation candidate\n",
            "Requirement already satisfied: libarchive in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from libarchive) (1.3.7)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot) (3.2.1)\n",
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.7)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "sns.set(style='darkgrid')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:29:42.172008Z",
          "iopub.execute_input": "2024-11-03T05:29:42.172434Z",
          "iopub.status.idle": "2024-11-03T05:29:53.038744Z",
          "shell.execute_reply.started": "2024-11-03T05:29:42.172403Z",
          "shell.execute_reply": "2024-11-03T05:29:53.037462Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "2WOqHW3NrJvq",
        "outputId": "c9b2856b-4aa4-4677-fbb4-3d7c2aa57395"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.keras.layers.experimental'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-75b94e37748a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# System libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Setting the seed ensures that the random processes involved in training and testing models are initialized in the same state each time the code is executed. This helps in reducing randomness and making the results consistent across different runs."
      ],
      "metadata": {
        "id": "3DxLKUH1rJvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed Everything to reproduce results for future use cases\n",
        "def seed_everything(seed=42):\n",
        "    # Seed value for TensorFlow\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Seed value for NumPy\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Seed value for Python's random library\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Force TensorFlow to use single thread\n",
        "    # Multiple threads are a potential source of non-reproducible results.\n",
        "    session_conf = tf.compat.v1.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1\n",
        "    )\n",
        "\n",
        "    # Make sure that TensorFlow uses a deterministic operation wherever possible\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:30:04.279249Z",
          "iopub.execute_input": "2024-11-03T05:30:04.279785Z",
          "iopub.status.idle": "2024-11-03T05:30:04.288773Z",
          "shell.execute_reply.started": "2024-11-03T05:30:04.279746Z",
          "shell.execute_reply": "2024-11-03T05:30:04.287220Z"
        },
        "trusted": true,
        "id": "ntTmShMprJvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:30:07.618794Z",
          "iopub.execute_input": "2024-11-03T05:30:07.619373Z",
          "iopub.status.idle": "2024-11-03T05:30:08.467451Z",
          "shell.execute_reply.started": "2024-11-03T05:30:07.619328Z",
          "shell.execute_reply": "2024-11-03T05:30:08.466289Z"
        },
        "trusted": true,
        "id": "YRd8RiWwrJvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Download Helper Functions and Import"
      ],
      "metadata": {
        "id": "ADBPdhuCrJvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Import the Dataset"
      ],
      "metadata": {
        "id": "sXGpRNFGrJvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### We create a bunch of helpful functions throughout the course.\n",
        "### Storing them here so they're easily accessible.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "\n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "# Create function to unzip a zipfile into current working directory\n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:33:28.514210Z",
          "iopub.execute_input": "2024-11-03T05:33:28.514681Z",
          "iopub.status.idle": "2024-11-03T05:33:28.559278Z",
          "shell.execute_reply.started": "2024-11-03T05:33:28.514645Z",
          "shell.execute_reply": "2024-11-03T05:33:28.557679Z"
        },
        "trusted": true,
        "id": "rsJezqa6rJvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:31:18.397724Z",
          "iopub.execute_input": "2024-11-03T05:31:18.398252Z",
          "iopub.status.idle": "2024-11-03T05:31:39.661750Z",
          "shell.execute_reply.started": "2024-11-03T05:31:18.398210Z",
          "shell.execute_reply": "2024-11-03T05:31:39.659671Z"
        },
        "trusted": true,
        "id": "vVx-zzfGrJvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"/kaggle/input/agricultural-pests-image-dataset\"\n",
        "walk_through_dir(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:33:38.656856Z",
          "iopub.execute_input": "2024-11-03T05:33:38.657319Z",
          "iopub.status.idle": "2024-11-03T05:33:40.411658Z",
          "shell.execute_reply.started": "2024-11-03T05:33:38.657285Z",
          "shell.execute_reply": "2024-11-03T05:33:40.410511Z"
        },
        "trusted": true,
        "id": "2n93cNGrrJvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Pest Images"
      ],
      "metadata": {
        "id": "rF45FQwIrJvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "# Step 2: Print 5 Images from Each Pest Subfolder\n",
        "\n",
        "# Loop through each pest subfolder\n",
        "for folder_name in os.listdir(dataset):\n",
        "    folder_path = os.path.join(dataset, folder_name)\n",
        "\n",
        "    # Check if the current item is a directory (pest subfolder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Get a list of all images in the current pest subfolder\n",
        "        images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        # Randomly select 5 images from the list\n",
        "        selected_images = random.sample(images, 5)\n",
        "\n",
        "        # Print the selected images in multiple columns\n",
        "        fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "        fig.suptitle(folder_name)\n",
        "\n",
        "        for i, image_name in enumerate(selected_images):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "            axes[i].imshow(image)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:33:44.303401Z",
          "iopub.execute_input": "2024-11-03T05:33:44.304298Z",
          "iopub.status.idle": "2024-11-03T05:33:53.361966Z",
          "shell.execute_reply.started": "2024-11-03T05:33:44.304259Z",
          "shell.execute_reply": "2024-11-03T05:33:53.360704Z"
        },
        "trusted": true,
        "id": "et8owW78rJvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> Create a dataframe of the pests with the image path and the labels"
      ],
      "metadata": {
        "id": "OV34GgjvrJvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create DataFrame and Store Data\n",
        "\n",
        "# Initialize lists to store image paths and corresponding labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Loop through each pest subfolder\n",
        "for folder_name in os.listdir(dataset):\n",
        "    folder_path = os.path.join(dataset, folder_name)\n",
        "\n",
        "    # Check if the current item is a directory (pest subfolder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Get a list of all images in the current pest subfolder\n",
        "        images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        for image_name in images:\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            image_paths.append(image_path)\n",
        "            labels.append(folder_name)\n",
        "\n",
        "# Create a DataFrame from the collected data\n",
        "data = {\n",
        "    'image_path': image_paths,\n",
        "    'label': labels\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:02.584991Z",
          "iopub.execute_input": "2024-11-03T05:34:02.585393Z",
          "iopub.status.idle": "2024-11-03T05:34:02.642260Z",
          "shell.execute_reply.started": "2024-11-03T05:34:02.585363Z",
          "shell.execute_reply": "2024-11-03T05:34:02.640765Z"
        },
        "trusted": true,
        "id": "DQ2_3r8DrJvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Let us plot the distribution characteristics of the pests"
      ],
      "metadata": {
        "id": "i9pGTMXvrJvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# Plot the label distribution as a bar plot using Seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.set(style='whitegrid')  # Use a white grid background\n",
        "\n",
        "# Generate the bar plot\n",
        "sns.barplot(x=df['label'].value_counts().index, y=df['label'].value_counts().values)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Label', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Pest Distribution', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:08.517380Z",
          "iopub.execute_input": "2024-11-03T05:34:08.517959Z",
          "iopub.status.idle": "2024-11-03T05:34:09.125087Z",
          "shell.execute_reply.started": "2024-11-03T05:34:08.517914Z",
          "shell.execute_reply": "2024-11-03T05:34:09.123767Z"
        },
        "trusted": true,
        "id": "eCLRluD4rJvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### It can be seen that last 4 pests have less images than others. The imbalance is not as dominant so we will leave it as it is."
      ],
      "metadata": {
        "id": "UYTraPOirJvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Splitting and Data Generator"
      ],
      "metadata": {
        "id": "N9aCXRyyrJvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate in train and test data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:19.625756Z",
          "iopub.execute_input": "2024-11-03T05:34:19.626169Z",
          "iopub.status.idle": "2024-11-03T05:34:19.634924Z",
          "shell.execute_reply.started": "2024-11-03T05:34:19.626137Z",
          "shell.execute_reply": "2024-11-03T05:34:19.633766Z"
        },
        "trusted": true,
        "id": "Zf4Q-wCbrJvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:25.113075Z",
          "iopub.execute_input": "2024-11-03T05:34:25.113592Z",
          "iopub.status.idle": "2024-11-03T05:34:25.120987Z",
          "shell.execute_reply.started": "2024-11-03T05:34:25.113536Z",
          "shell.execute_reply": "2024-11-03T05:34:25.119503Z"
        },
        "trusted": true,
        "id": "dzuNKCwfrJvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into three categories.\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:28.299460Z",
          "iopub.execute_input": "2024-11-03T05:34:28.299951Z",
          "iopub.status.idle": "2024-11-03T05:34:31.411646Z",
          "shell.execute_reply.started": "2024-11-03T05:34:28.299915Z",
          "shell.execute_reply": "2024-11-03T05:34:31.410472Z"
        },
        "trusted": true,
        "id": "GyxiP-EurJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "WQwTkY00rJvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Data Augmentation Step\n",
        "augment = Sequential([\n",
        "    RandomFlip(\"horizontal\"),            # Random horizontal flipping\n",
        "    RandomRotation(factor=0.2),          # Random rotation up to 20 degrees\n",
        "    RandomZoom(height_factor=0.1, width_factor=0.1),  # Random zooming up to 10%\n",
        "    RandomContrast(factor=0.1),          # Random contrast adjustment up to 10%\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:34:31.413931Z",
          "iopub.execute_input": "2024-11-03T05:34:31.414395Z",
          "iopub.status.idle": "2024-11-03T05:34:31.509793Z",
          "shell.execute_reply.started": "2024-11-03T05:34:31.414331Z",
          "shell.execute_reply": "2024-11-03T05:34:31.508754Z"
        },
        "trusted": true,
        "id": "TXuInU20rJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading of a pretrained ResNet50 Model"
      ],
      "metadata": {
        "id": "4a_jzZElrJvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "resnet_model = ResNet50(\n",
        "    include_top=False,\n",
        "    weights='/kaggle/input/resnet50/tensorflow2/default/1/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "resnet_model.trainable = False\n",
        "\n",
        "# Create checkpoint callback\n",
        "checkpoint_path = \"pests_cats_classification_model_checkpoint\"\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
        "                                      save_weights_only=True,\n",
        "                                      monitor=\"val_accuracy\",\n",
        "                                      save_best_only=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:38:28.838177Z",
          "iopub.execute_input": "2024-11-03T05:38:28.838769Z",
          "iopub.status.idle": "2024-11-03T05:38:31.987518Z",
          "shell.execute_reply.started": "2024-11-03T05:38:28.838726Z",
          "shell.execute_reply": "2024-11-03T05:38:31.986450Z"
        },
        "trusted": true,
        "id": "1gkWy37arJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 5 epochs\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\",  # watch the validation loss metric\n",
        "                               patience=5,         # stop training if no improvement for 5 epochs\n",
        "                               restore_best_weights=True)  # restore best weights based on validation loss\n",
        "\n",
        "# Add additional layers for the custom head of the model\n",
        "inputs = resnet_model.input\n",
        "x = augment(inputs)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal')(inputs)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\n",
        "x = resnet_model(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "outputs = Dense(12, activation='softmax')(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:39:15.518834Z",
          "iopub.execute_input": "2024-11-03T05:39:15.519349Z",
          "iopub.status.idle": "2024-11-03T05:39:17.091952Z",
          "shell.execute_reply.started": "2024-11-03T05:39:15.519309Z",
          "shell.execute_reply": "2024-11-03T05:39:17.090765Z"
        },
        "trusted": true,
        "id": "kTaMwtCyrJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "qBr9Fy4OrJvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=5,\n",
        "    callbacks=[\n",
        "        early_stopping,\n",
        "        checkpoint_callback\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T05:40:12.839465Z",
          "iopub.execute_input": "2024-11-03T05:40:12.839960Z"
        },
        "trusted": true,
        "id": "b0HVNNStrJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> We can see the training has stopped early because there is no significant increase in the accuracy and it is wastefull to go for more epochs"
      ],
      "metadata": {
        "id": "u8Y5cFjlrJvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, steps=len(test_images))\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T15:46:59.455417Z",
          "iopub.execute_input": "2023-07-20T15:46:59.455839Z",
          "iopub.status.idle": "2023-07-20T15:47:09.988767Z",
          "shell.execute_reply.started": "2023-07-20T15:46:59.455807Z",
          "shell.execute_reply": "2023-07-20T15:47:09.987717Z"
        },
        "trusted": true,
        "id": "ZFKdbAObrJvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> We have got an accuracy of 83 % which is not too bad."
      ],
      "metadata": {
        "id": "IsZKHYUJrJvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "## Visualize the accuracy and loss plots"
      ],
      "metadata": {
        "id": "PA8cVVhvrJvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Training and Validation Loss', fontsize=16)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T15:47:40.720995Z",
          "iopub.execute_input": "2023-07-20T15:47:40.72139Z",
          "iopub.status.idle": "2023-07-20T15:47:41.120919Z",
          "shell.execute_reply.started": "2023-07-20T15:47:40.72136Z",
          "shell.execute_reply": "2023-07-20T15:47:41.120004Z"
        },
        "trusted": true,
        "id": "S_9-BS2frJvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T15:48:02.967795Z",
          "iopub.execute_input": "2023-07-20T15:48:02.968194Z",
          "iopub.status.idle": "2023-07-20T15:48:03.38196Z",
          "shell.execute_reply.started": "2023-07-20T15:48:02.96816Z",
          "shell.execute_reply": "2023-07-20T15:48:03.381044Z"
        },
        "trusted": true,
        "id": "3eTfoUFcrJvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> Here it can be seen that the model is performing better on validation data which indicates the model is not overfitting\n",
        "    "
      ],
      "metadata": {
        "id": "DZm_nf7hrJvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Predictions"
      ],
      "metadata": {
        "id": "yXRs5NbfrJvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['beetle', 'grasshopper', 'earthworms', 'ants', 'earwig', 'snail',\n",
        "       'catterpillar', 'weevil', 'bees', 'moth', 'wasp', 'slug']  # Replace with your actual class names\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convert the predicted probabilities to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true labels from the test data generator\n",
        "true_labels = test_images.classes\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "accuracy = np.mean(predicted_labels == true_labels)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Print some sample predictions along with true labels\n",
        "num_samples = 10\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(num_samples):\n",
        "    print(\"True Label:\", class_names[true_labels[i]], \"| Predicted Label:\", class_names[predicted_labels[i]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T15:55:13.207033Z",
          "iopub.execute_input": "2023-07-20T15:55:13.207411Z",
          "iopub.status.idle": "2023-07-20T15:55:16.864841Z",
          "shell.execute_reply.started": "2023-07-20T15:55:13.207383Z",
          "shell.execute_reply": "2023-07-20T15:55:16.863763Z"
        },
        "trusted": true,
        "id": "_lO29qB7rJvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The predictions are very good"
      ],
      "metadata": {
        "id": "_bVwsDjArJvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification report and Confusion Matrix"
      ],
      "metadata": {
        "id": "Nx_tqYVorJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "class_names = ['beetle', 'grasshopper', 'earthworms', 'ants', 'earwig', 'snail','catterpillar', 'weevil']\n",
        "# Get a batch of test data (you can adjust the batch size as needed)\n",
        "batch_size = 10\n",
        "test_data = next(iter(test_images))\n",
        "images = test_data[0][:batch_size]  # Get the images from the test data batch\n",
        "true_labels = test_data[1][:batch_size]  # Get the true labels from the test data batch\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert the one-hot encoded true_labels to class indices\n",
        "true_labels = np.argmax(true_labels, axis=1)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:21:55.558747Z",
          "iopub.execute_input": "2023-07-20T16:21:55.559154Z",
          "iopub.status.idle": "2023-07-20T16:21:56.406973Z",
          "shell.execute_reply.started": "2023-07-20T16:21:55.559119Z",
          "shell.execute_reply": "2023-07-20T16:21:56.405768Z"
        },
        "trusted": true,
        "id": "T1lUKQ4drJvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading of a pretrained InceptionV3 Model"
      ],
      "metadata": {
        "id": "7BDWHlVfrJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "# Load the pretained model\n",
        "pretrained_model = InceptionV3(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = True\n",
        "\n",
        "# Create checkpoint callback\n",
        "checkpoint_path = \"pests_cats_classification_model_checkpoint\"\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
        "                                      save_weights_only=True,\n",
        "                                      monitor=\"val_accuracy\",\n",
        "                                      save_best_only=True)\n",
        "\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 5 epochs\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\",  # watch the validation loss metric\n",
        "                               patience=5,         # stop training if no improvement for 5 epochs\n",
        "                               restore_best_weights=True)  # restore best weights based on validation loss\n",
        "\n",
        "# Add additional layers for the custom head of the model\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = augment(inputs)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal')(x)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\n",
        "x = pretrained_model(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "outputs = Dense(12, activation='softmax')(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:33:22.433802Z",
          "iopub.execute_input": "2023-07-20T16:33:22.434308Z",
          "iopub.status.idle": "2023-07-20T16:33:25.828163Z",
          "shell.execute_reply.started": "2023-07-20T16:33:22.434267Z",
          "shell.execute_reply": "2023-07-20T16:33:25.827112Z"
        },
        "trusted": true,
        "id": "_e1kn-LTrJvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IneptionV3 Model Training\n"
      ],
      "metadata": {
        "id": "kNKukdYWrJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        early_stopping,\n",
        "        checkpoint_callback\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:33:25.830155Z",
          "iopub.execute_input": "2023-07-20T16:33:25.830503Z",
          "iopub.status.idle": "2023-07-20T16:41:48.834267Z",
          "shell.execute_reply.started": "2023-07-20T16:33:25.83047Z",
          "shell.execute_reply": "2023-07-20T16:41:48.833259Z"
        },
        "trusted": true,
        "id": "u2m3WxtqrJvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, steps=len(test_images))\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:42:38.232894Z",
          "iopub.execute_input": "2023-07-20T16:42:38.233303Z",
          "iopub.status.idle": "2023-07-20T16:42:48.638932Z",
          "shell.execute_reply.started": "2023-07-20T16:42:38.23327Z",
          "shell.execute_reply": "2023-07-20T16:42:48.637785Z"
        },
        "trusted": true,
        "id": "Cp4XXer2rJvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> The accuracy has been increased from 82 to 86 % with respect to InceptionV3 model"
      ],
      "metadata": {
        "id": "af8aV9LsrJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Training and Validation Loss', fontsize=16)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:43:35.567449Z",
          "iopub.execute_input": "2023-07-20T16:43:35.567845Z",
          "iopub.status.idle": "2023-07-20T16:43:35.954926Z",
          "shell.execute_reply.started": "2023-07-20T16:43:35.567813Z",
          "shell.execute_reply": "2023-07-20T16:43:35.953979Z"
        },
        "trusted": true,
        "id": "Gpckya5urJv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:43:46.216546Z",
          "iopub.execute_input": "2023-07-20T16:43:46.216924Z",
          "iopub.status.idle": "2023-07-20T16:43:46.608674Z",
          "shell.execute_reply.started": "2023-07-20T16:43:46.216893Z",
          "shell.execute_reply": "2023-07-20T16:43:46.606995Z"
        },
        "trusted": true,
        "id": "lWa8ssXwrJv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\"> After 6 epochs, the loss is increasing and the accuracy of the validation set is decreasing. That is where earlystopping comes into play."
      ],
      "metadata": {
        "id": "bMwI_rfMrJv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionV3 model prediction"
      ],
      "metadata": {
        "id": "qeH4q3VtrJv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['beetle', 'grasshopper', 'earthworms', 'ants', 'earwig', 'snail',\n",
        "       'catterpillar', 'weevil', 'bees', 'moth', 'wasp', 'slug']  # Replace with your actual class names\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convert the predicted probabilities to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true labels from the test data generator\n",
        "true_labels = test_images.classes\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "accuracy = np.mean(predicted_labels == true_labels)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Print some sample predictions along with true labels\n",
        "num_samples = 10\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(num_samples):\n",
        "    print(\"True Label:\", class_names[true_labels[i]], \"| Predicted Label:\", class_names[predicted_labels[i]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-20T16:44:08.774772Z",
          "iopub.execute_input": "2023-07-20T16:44:08.775163Z",
          "iopub.status.idle": "2023-07-20T16:44:13.125656Z",
          "shell.execute_reply.started": "2023-07-20T16:44:08.775131Z",
          "shell.execute_reply": "2023-07-20T16:44:13.124712Z"
        },
        "trusted": true,
        "id": "cjUgXUASrJv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">In this Kaggle notebook, we delved into the exciting domain of agricultural pest classification using deep learning techniques. Our main goal was to assist farmers in effectively identifying and managing common agricultural pests, which can significantly impact crop yield and quality.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Throughout the project, we employed two powerful pre-trained deep learning models, ResNet and InceptionV3, to tackle the pest classification task. After thorough data preprocessing and augmentation, we fine-tuned both models using transfer learning techniques, leveraging their pre-trained knowledge for our specific agricultural pest classification.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Upon evaluation, we observed that the InceptionV3 model outperformed ResNet, achieving an impressive accuracy of 86%. This notable improvement from 82% demonstrated the superiority of the InceptionV3 architecture for our classification task. By automating the pest identification process, our deep learning models offer a reliable and efficient tool for farmers to identify and manage agricultural pests. This technology can significantly contribute to sustainable agriculture practices, ensuring timely pest detection and precise management.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">In conclusion, this project showcases the potential of deep learning in addressing real-world challenges faced by the agricultural sector. With continued research and innovation, we can harness the power of AI to enhance precision agriculture and contribute to global food security.\n",
        "\n",
        "<p style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #333333;text-align: justify;\">Let's continue exploring the realms of artificial intelligence and its applications in various fields, driving positive change and advancements for a better tomorrow. Happy learning and happy farming!"
      ],
      "metadata": {
        "id": "cOTBiUEcrJv0"
      }
    }
  ]
}